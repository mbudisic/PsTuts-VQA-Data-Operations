{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Create a golden dataset using RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "import getpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "def set_api_key_if_not_present(key_name, prompt_message):\n",
    "    if key_name not in os.environ or not os.environ[key_name]:\n",
    "        os.environ[key_name] = getpass.getpass(prompt_message)\n",
    "\n",
    "set_api_key_if_not_present(\"OPENAI_API_KEY\", \"OpenAI API Key:\")\n",
    "set_api_key_if_not_present(\"TAVILY_API_KEY\", \"TAVILY_API_KEY:\")\n",
    "set_api_key_if_not_present(\"LANGCHAIN_API_KEY\", \"LANGCHAIN_API_KEY:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to load all of our transcripts in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import Dict\n",
    "import loader\n",
    "import requests\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "url = \"https://huggingface.co/datasets/mbudisic/PsTuts-VQA/raw/main/train.json\"\n",
    "\n",
    "def load_VQA_file_from_url(url:str) -> Tuple[List[Document], str, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Loads a VQA dataset file from a URL and processes it into documents.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL pointing to a JSON file containing VQA dataset\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list[Document]: Processed documents from the VideoTranscriptBulkLoader\n",
    "            - str: Group name extracted from the URL filename\n",
    "            - List[Dict]: The raw JSON payload loaded from the URL\n",
    "            \n",
    "    Note:\n",
    "        This function needs to be updated as it currently has a type mismatch.\n",
    "        The return type annotation indicates List[Document] but it returns a tuple.\n",
    "    \"\"\"\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    group = url.split('/')[-1].split('.')[0]\n",
    "    json_payload = loader.load_json_string(resp.content.decode('utf-8'), group)\n",
    "    docs = loader.VideoTranscriptBulkLoader(json_payload=json_payload).load()\n",
    "    return docs, group, json_payload\n",
    "\n",
    "\n",
    "train,group_name,json_payload = load_VQA_file_from_url(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are all data keys. `group` indicates the filename the transcript was loaded from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 54\n",
      "File data fields: dict_keys(['video_id', 'title', 'desc', 'length', 'url', 'transcripts', 'qa', 'group'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of files: {len(json_payload)}\")\n",
    "print(f\"File data fields: {json_payload[0].keys()}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each file, `transcripts` field is a list of transcript chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts in first file: 111\n",
      "Transcript keys: dict_keys(['sent_id', 'sent', 'begin', 'end'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transcripts in first file: {len(json_payload[0]['transcripts'])}\")\n",
    "print(f\"Transcript keys: {json_payload[0]['transcripts'][0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used the loader for 1 document-per-video (as opposed to 1 document\n",
    "per phrase, which is the granular form of transcripts\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents: 54. # of videos: 54\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of documents: {len(train)}. # of videos: {len(json_payload)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the knowledge graph\n",
    "\n",
    "For the sake of the notebook, we'll demo here how to create a knowledge graph.\n",
    "\n",
    "At the end, we will call all of this from a function in `golden_dataset.py` to automate\n",
    "creation of the knowledge graph and queries from an arbitrary collection of documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the 54 documents is substantial for our needs. We can trim it down to about half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = train\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.persona import Persona\n",
    "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to generate the knowledge graph and queries using `gpt-4.1` as the\n",
    "generating model, and `text-embedding-3-small` as the embedding model`.\n",
    "This is a rare enough call that we can afford calling more powerful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "generator_llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "embedding_model:Embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(embedding_model.model)\n",
    "\n",
    "wrapped_generator_llm = LangchainLLMWrapper(generator_llm)\n",
    "wrapped_embedding_model = LangchainEmbeddingsWrapper(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kg_train_text_embed.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "root = Path(\".\")\n",
    "kg_filename = Path(f\"kg_{group_name}_text_embed.json\")\n",
    "kg_path = root.joinpath(kg_filename)\n",
    "print(kg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kg_train_text_embed.json does not contain a knowledge graph. Generating.\n",
      "Initial size KnowledgeGraph(nodes: 54, relationships: 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcc4935faac4defa64f4f5259d9cddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02c7d4d5a264d80b97268c29399a289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe983218a5d41f4ad2ab70ae3281b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '15cabb'. Skipping!\n",
      "Property 'summary' already exists in node '29021d'. Skipping!\n",
      "Property 'summary' already exists in node 'e6751c'. Skipping!\n",
      "Property 'summary' already exists in node '249d07'. Skipping!\n",
      "Property 'summary' already exists in node '109999'. Skipping!\n",
      "Property 'summary' already exists in node '94fbc3'. Skipping!\n",
      "Property 'summary' already exists in node '7f504f'. Skipping!\n",
      "Property 'summary' already exists in node '90f441'. Skipping!\n",
      "Property 'summary' already exists in node '2c0f75'. Skipping!\n",
      "Property 'summary' already exists in node 'f96757'. Skipping!\n",
      "Property 'summary' already exists in node '72482d'. Skipping!\n",
      "Property 'summary' already exists in node '16476a'. Skipping!\n",
      "Property 'summary' already exists in node 'b79fa9'. Skipping!\n",
      "unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-4OzneGxZmntU4Fq9wJeB1LE6 on tokens per min (TPM): Limit 30000, Used 29357, Requested 1566. Please try again in 1.846s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-4OzneGxZmntU4Fq9wJeB1LE6 on tokens per min (TPM): Limit 30000, Used 29744, Requested 1566. Please try again in 2.62s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Property 'summary' already exists in node '864bef'. Skipping!\n",
      "Property 'summary' already exists in node '086680'. Skipping!\n",
      "Property 'summary' already exists in node '764038'. Skipping!\n",
      "Property 'summary' already exists in node 'a3d74b'. Skipping!\n",
      "Property 'summary' already exists in node '51f329'. Skipping!\n",
      "Property 'summary' already exists in node '4c64b7'. Skipping!\n",
      "Property 'summary' already exists in node 'f480a5'. Skipping!\n",
      "Property 'summary' already exists in node 'e7b08f'. Skipping!\n",
      "unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-4OzneGxZmntU4Fq9wJeB1LE6 on tokens per min (TPM): Limit 30000, Used 29800, Requested 1447. Please try again in 2.494s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Property 'summary' already exists in node '9578b6'. Skipping!\n",
      "Property 'summary' already exists in node '62f5be'. Skipping!\n",
      "Property 'summary' already exists in node '6cbd8c'. Skipping!\n",
      "Property 'summary' already exists in node '676ad8'. Skipping!\n",
      "unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-4OzneGxZmntU4Fq9wJeB1LE6 on tokens per min (TPM): Limit 30000, Used 28825, Requested 2003. Please try again in 1.656s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Property 'summary' already exists in node '59bb7d'. Skipping!\n",
      "Property 'summary' already exists in node 'bd2a6f'. Skipping!\n",
      "Property 'summary' already exists in node 'd1a2dc'. Skipping!\n",
      "Property 'summary' already exists in node 'f3b3b8'. Skipping!\n",
      "Property 'summary' already exists in node '04a4cd'. Skipping!\n",
      "Property 'summary' already exists in node 'c6066b'. Skipping!\n",
      "Property 'summary' already exists in node 'ff036a'. Skipping!\n",
      "Property 'summary' already exists in node '1dfeef'. Skipping!\n",
      "Property 'summary' already exists in node '1a8dd9'. Skipping!\n",
      "Property 'summary' already exists in node '0a41f2'. Skipping!\n",
      "Property 'summary' already exists in node 'dd1da7'. Skipping!\n",
      "Property 'summary' already exists in node '3eac27'. Skipping!\n",
      "Property 'summary' already exists in node '8125fc'. Skipping!\n",
      "Property 'summary' already exists in node '658133'. Skipping!\n",
      "Property 'summary' already exists in node '065a44'. Skipping!\n",
      "Property 'summary' already exists in node '8f9e49'. Skipping!\n",
      "Property 'summary' already exists in node '114c69'. Skipping!\n",
      "Property 'summary' already exists in node '12e4ea'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bd74b3951749b4a392b78d78297106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node 54211285-5248-40b9-93f9-997ad2ea0592 does not have a summary. Skipping filtering.\n",
      "Node 08a19371-c407-479e-946d-40a1a87fbc4e does not have a summary. Skipping filtering.\n",
      "Node bd0631e5-c78c-4bcb-80e7-d778e3fdf325 does not have a summary. Skipping filtering.\n",
      "Node 5c82fe5c-472b-4dfd-a944-56f69e938b57 does not have a summary. Skipping filtering.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa02738e62c34a04a5e00182c31607de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '15cabb'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '29021d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0c4fa2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '249d07'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e6751c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f96757'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '109999'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '94fbc3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2c0f75'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7f504f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '90f441'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '12e4ea'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8125fc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '72482d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b79fa9'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '16476a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '864bef'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2aa680'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '658133'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '086680'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '764038'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a3d74b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f480a5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '51f329'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '59bb7d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4c64b7'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e7b08f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '114c69'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '62f5be'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9578b6'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6cbd8c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8f9e49'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd1a2dc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '676ad8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '04a4cd'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '065a44'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'bd2a6f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f3b3b8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3eac27'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0a41f2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c6066b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ff036a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1dfeef'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1a8dd9'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'dd1da7'. Skipping!\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f037fa983234d50b363e9bb686506a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: Node c4c71ba9-552c-48c4-8f58-5317779830cc has no summary_embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transformations size KnowledgeGraph(nodes: 110, relationships: 27)\n",
      "Saved to kg_train_text_embed.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 110, relationships: 27)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from email import generator\n",
    "\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "try:\n",
    "    kg = kg.load(kg_path)\n",
    "    print(f\"Loaded from {kg_path}.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"{kg_path} does not contain a knowledge graph. Generating.\")\n",
    "    for doc in docs:\n",
    "        kg.nodes.append(\n",
    "            Node(\n",
    "                type=NodeType.DOCUMENT,\n",
    "                properties={\"page_content\": doc.page_content, \n",
    "                            \"document_metadata\": doc.metadata}\n",
    "            )\n",
    "        )\n",
    "    print(f\"Initial size {str(kg)}\")\n",
    "    transforms = default_transforms(documents=docs, \n",
    "                                            llm=wrapped_generator_llm, \n",
    "                                            embedding_model=wrapped_embedding_model)\n",
    "    apply_transforms(kg, transforms)\n",
    "    print(f\"After transformations size {str(kg)}\")\n",
    "    kg.save(kg_path)\n",
    "    print(f\"Saved to {kg_path}.\")\n",
    "    \n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = [\n",
    "    Persona(\n",
    "    name=\"Beginner Photoshop User\",\n",
    "    role_description=(\"Beginner Photoshop user, learning to complete \"\n",
    "                      \"simple tasks, use the tools in Photoshop \"\n",
    "                      \"and navigate the graphical user interface\"),\n",
    "),\n",
    "    Persona(\n",
    "    name=\"Photoshop trainer\",\n",
    "    role_description=(\"Experienced trainer in Photoshop. Looking to develop\"\n",
    "                      \"step-by-step guides for Photoshop beginners\"),\n",
    ")\n",
    "]\n",
    "\n",
    "generator = TestsetGenerator(llm=wrapped_generator_llm, \n",
    "                             embedding_model=wrapped_embedding_model, \n",
    "                             persona_list=personas,\n",
    "                             knowledge_graph=kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=wrapped_generator_llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=wrapped_generator_llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=wrapped_generator_llm), 0.25),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# testset = generator.generate(\n",
    "#     testset_size=100, \n",
    "#     batch_size=8,\n",
    "#     num_personas=len(personas),\n",
    "#     query_distribution=query_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function create_golden_dataset.create_golden_dataset(docs: List[langchain_core.documents.base.Document], testset_size, group_name: str = '', filename: str = '', generator_llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7af5b5524dd0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7af5b552a250>, root_client=<openai.OpenAI object at 0x7af5b5526690>, root_async_client=<openai.AsyncOpenAI object at 0x7af5b5525090>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********')), embedding_model: langchain_core.embeddings.embeddings.Embeddings = OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x7af5b552d6d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7af5b552e250>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True), kg: ragas.testset.graph.KnowledgeGraph | None = None)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import create_golden_dataset\n",
    "\n",
    "create_golden_dataset.create_golden_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kg_test.json\n",
      "Initial size KnowledgeGraph(nodes: 11, relationships: 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6f77116a874dfdbd8409e43d6b5011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eefb99eb9c74b129b1f6cd0f575b29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf51aa2a58884ce98e67eefde3f7d047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n",
      "unable to apply transformation: 'LangchainLLMWrapper' object has no attribute 'agenerate_prompt'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7b5a3c6df44366a65d3840e90bae92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64399d8f7884609b1667d1dab852a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b204d99a700f495ab6a958d74b65c27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: Node ecdd3922-3b08-4652-aafd-46e56ed225af has no summary_embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transformations size KnowledgeGraph(nodes: 11, relationships: 0)\n",
      "TestsetGenerator(llm=LangchainLLMWrapper(langchain_llm=LangchainLLMWrapper(...)), embedding_model=LangchainEmbeddingsWrapper(embeddings=LangchainEmbeddingsWrapper(...)), knowledge_graph=KnowledgeGraph(nodes: 11, relationships: 0), persona_list=[Persona(name='Beginner Photoshop User', role_description='Beginner Photoshop user, learning to complete simple tasks, use the tools in Photoshop and navigate the graphical user interface'), Persona(name='Photoshop trainer', role_description='Experienced trainer in Photoshop. Looking to developstep-by-step guides for Photoshop beginners')])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf51aa5d18941fa806ad4d419abe458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8b790011474f38902774975fc65a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1/1:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "No clusters found in the knowledge graph. Try changing the relationship condition.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m test_docs,_,_ = load_VQA_file_from_url(\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/datasets/mbudisic/PsTuts-VQA/raw/main/test.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m test_dataset= \u001b[43mcreate_golden_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_golden_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator_llm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrapped_generator_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrapped_embedding_model\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/create_golden_dataset.py:132\u001b[39m, in \u001b[36mcreate_golden_dataset\u001b[39m\u001b[34m(docs, testset_size, group_name, filename, generator_llm, embedding_model, kg)\u001b[39m\n\u001b[32m    124\u001b[39m query_distribution = [\n\u001b[32m    125\u001b[39m     (SingleHopSpecificQuerySynthesizer(llm=wrapped_generator_llm), \u001b[32m0.5\u001b[39m),\n\u001b[32m    126\u001b[39m     (MultiHopAbstractQuerySynthesizer(llm=wrapped_generator_llm), \u001b[32m0.25\u001b[39m),\n\u001b[32m    127\u001b[39m     (MultiHopSpecificQuerySynthesizer(llm=wrapped_generator_llm), \u001b[32m0.25\u001b[39m),\n\u001b[32m    128\u001b[39m ]\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m testset = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_personas\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpersonas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m testset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/testset/synthesizers/generate.py:413\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    412\u001b[39m     scenario_generation_rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    415\u001b[39m     scenario_generation_rm.on_chain_end(\n\u001b[32m    416\u001b[39m         outputs={\u001b[33m\"\u001b[39m\u001b[33mscenario_sample_list\u001b[39m\u001b[33m\"\u001b[39m: scenario_sample_list}\n\u001b[32m    417\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/testset/synthesizers/generate.py:410\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    401\u001b[39m     exec.submit(\n\u001b[32m    402\u001b[39m         scenario.generate_scenarios,\n\u001b[32m    403\u001b[39m         n=splits[i],\n\u001b[32m   (...)\u001b[39m\u001b[32m    406\u001b[39m         callbacks=scenario_generation_grp,\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     scenario_sample_list: t.List[t.List[BaseScenario]] = \u001b[43mexec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    412\u001b[39m     scenario_generation_rm.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/executor.py:180\u001b[39m, in \u001b[36mExecutor._process_jobs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    176\u001b[39m coroutines = [\n\u001b[32m    177\u001b[39m     afunc(*args, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m afunc, args, kwargs, _ \u001b[38;5;129;01min\u001b[39;00m batch\n\u001b[32m    178\u001b[39m ]\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m as_completed(coroutines, max_workers):\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    181\u001b[39m     results.append(result)\n\u001b[32m    182\u001b[39m     overall_pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py:615\u001b[39m, in \u001b[36mas_completed.<locals>._wait_for_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    613\u001b[39m     \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/executor.py:48\u001b[39m, in \u001b[36mas_completed.<locals>.sema_coro\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msema_coro\u001b[39m(coro):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/executor.py:100\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_exceptions:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m         exec_name = \u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/executor.py:96\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_callable_async\u001b[39m(\n\u001b[32m     93\u001b[39m     *args, **kwargs\n\u001b[32m     94\u001b[39m ) -> t.Tuple[\u001b[38;5;28mint\u001b[39m, t.Callable | \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(*args, **kwargs)\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m counter, result\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/testset/synthesizers/base.py:94\u001b[39m, in \u001b[36mBaseSynthesizer.generate_scenarios\u001b[39m\u001b[34m(self, n, knowledge_graph, persona_list, callbacks)\u001b[39m\n\u001b[32m     88\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m     89\u001b[39m scenario_generation_rm, scenario_generation_group = new_group(\n\u001b[32m     90\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m     91\u001b[39m     inputs={\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n, \u001b[33m\"\u001b[39m\u001b[33mknowledge_graph\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(knowledge_graph)},\n\u001b[32m     92\u001b[39m     callbacks=callbacks,\n\u001b[32m     93\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m scenarios = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_scenarios(\n\u001b[32m     95\u001b[39m     n, knowledge_graph, persona_list, scenario_generation_group\n\u001b[32m     96\u001b[39m )\n\u001b[32m     97\u001b[39m scenario_generation_rm.on_chain_end(outputs={\u001b[33m\"\u001b[39m\u001b[33mscenarios\u001b[39m\u001b[33m\"\u001b[39m: scenarios})\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scenarios\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PsTuts-VQA-Data-Operations/.venv/lib/python3.11/site-packages/ragas/testset/synthesizers/multi_hop/abstract.py:79\u001b[39m, in \u001b[36mMultiHopAbstractQuerySynthesizer._generate_scenarios\u001b[39m\u001b[34m(self, n, knowledge_graph, persona_list, callbacks)\u001b[39m\n\u001b[32m     76\u001b[39m scenarios = []\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node_clusters) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     80\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo clusters found in the knowledge graph. Try changing the relationship condition.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m     )\n\u001b[32m     82\u001b[39m num_sample_per_cluster = \u001b[38;5;28mint\u001b[39m(np.ceil(n / \u001b[38;5;28mlen\u001b[39m(node_clusters)))\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m node_clusters:\n",
      "\u001b[31mValueError\u001b[39m: No clusters found in the knowledge graph. Try changing the relationship condition."
     ]
    }
   ],
   "source": [
    "test_docs,_,_ = load_VQA_file_from_url(\"https://huggingface.co/datasets/mbudisic/PsTuts-VQA/raw/main/test.json\")\n",
    "\n",
    "test_dataset= create_golden_dataset.create_golden_dataset(\n",
    "    test_docs,\n",
    "    20,\n",
    "    group_name = \"test\",\n",
    "    generator_llm=wrapped_generator_llm,\n",
    "    embedding_model=wrapped_embedding_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()\n",
    "# ragas_dataset = testset.to_hf_dataset()\n",
    "# ragas_dataset.push_to_hub(\"mbudisic/pstuts_rag_qa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
